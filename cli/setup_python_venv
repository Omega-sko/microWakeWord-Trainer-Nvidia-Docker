#!/bin/bash
PROGDIR="$(dirname "$(realpath "$0")")"
ROOTDIR="$(dirname "${PROGDIR}")"

KNOWN_ARGS=( data-dir python gpu no-gpu )
source "${PROGDIR}/shell.functions"

if [ ${#UNKNOWN_ARGS[@]} -gt 0 ] ; then
    echo "Unknown argument(s): ${UNKNOWN_ARGS[*]}" >&2
    HELP=true
fi

if [ "${HELP}" == "true" ] ; then
    cat <<EOF >&2
Usage: setup_python_venv [ --gpu | --no-gpu ] [ --verbose ]

Options:
--gpu:     Install the GPU-capable versions of packages if available.  This
           is the default if the script detects that a GPU is available.

--no-gpu:  Install the non-GPU-capable versions of packages even if
           GPU-capable packages are available.  This is the default if the script
           detects that a GPU is NOT available.

--verbose: Print the detailed "pip install" output.

EOF
    exit 1
fi

[ -n "${DATA_DIR}" ] && DATA_DIR="$(realpath "${DATA_DIR}")"
[ -d  "${DATA_DIR}" ] || {
    echo "Data directory '${DATA_DIR}' doesn't exist." >&2
    exit 1
}

cd "${DATA_DIR}"

##### custom change
[ -z "${GPU}" ] && {
    GPU=false
    echo ""
    # Check multiple possible GPU device files for WSL2 compatibility
    if [ -c /dev/nvidiactl ]; then
        GPU=true
        echo "   Nvidia GPU detected via /dev/nvidiactl"
    elif [ -c /dev/dxg ]; then
        GPU=true
        # Check if nvidia-smi is available to confirm NVIDIA GPU
        if command -v nvidia-smi >/dev/null 2>&1; then
            echo "   NVIDIA GPU detected via WSL2 /dev/dxg + nvidia-smi"
        else
            echo "   GPU detected via WSL2 /dev/dxg (non-NVIDIA or no driver tools)"
        fi
    else
        # If no device files exist, GPU remains false
        echo "   No GPU device files found (/dev/nvidiactl or /dev/dxg)"
    fi
}

"${GPU}" || export CUDA_VISIBLE_DEVICES=-1

VENV="${DATA_DIR}/.venv"
#####custom change
# Deactivate venv only if command exists to avoid error
if [ -n "${VIRTUAL_ENV}" ] && command -v deactivate >/dev/null 2>&1; then
    deactivate
fi

if [ -n "${PYTHON}" ] ; then
    PYTHONS=( "${PYTHON}" )
    unset PYTHON
else
    # Add 3.11 as a common middle-ground (especially outside Ubuntu 24.04)
    PYTHONS=( python3.12 python3.11 python3.10 )
fi

for p in "${PYTHONS[@]}" ; do
    "${p}" --version &>/dev/null && { PYTHON="${p}" ; break ; }
done

[ -n "${PYTHON}" ] || {
    echo "A python 3.12/3.11/3.10 interpreter wasn't found. You'll need to install one before proceeding." >&2
    exit 1
}

if [ -d "${VENV}" ] ; then
    if [ -f "${DATA_DIR}/.mww-data-dir" ] ; then
        source "${VENV}/bin/activate" || {
            echo "Unable to activate existing virtualenv '${VENV}'. You should delete it and try again." >&2
            exit 1
        }
    else
        rm -rf "${VENV}"
    fi
fi

echo "===== Setting up Python environment ${VENV} ====="

if [ -z "$VIRTUAL_ENV" ] ; then
    echo "   ===== Creating new virtualenv at '${VENV}' ====="
else
    echo "   ===== Updating virtualenv at '${VENV}' ====="
fi

${PYTHON} -m venv --upgrade-deps "${VENV}"
source "${VENV}/bin/activate"

set -euo pipefail

# Symlink CLI scripts into .venv/bin
declare -a progfiles=( $(find "${PROGDIR}" -mindepth 1 -maxdepth 1 -executable -type f) )
progfiles+=( "${PROGDIR}/shell.functions" )

# Also symlink the top-level entrypoint if present
[ -x "${ROOTDIR}/train_wake_word" ] && progfiles+=( "${ROOTDIR}/train_wake_word" )

for f in "${progfiles[@]}" ; do
    ln -sfr "${f}" ".venv/bin/$(basename "${f}")"
done

#
# Pip doesn't process packages from requirements.txt in order but order is
# important because tensorflow, torch, onnxruntime and micro-wake-word all
# depend on CUDA packages at various versions. They need to be installed in
# this specific order or they may not be able to use the GPU.
#
export PIP_PROGRESS_BAR=off
export PIP_NO_COLOR=1
export PIP_QUIET=0

pip_install() {
    if $VERBOSE ; then
        pip install "$@" || return 1
    else
        { pip install "$@" || return 1 ; } | stdbuf -i0 -o0 tr -d '[:print:]' | stdbuf -i0 -o0 tr '\n' '.'
    fi
    echo
}

START_TS=$EPOCHSECONDS

echo "   ===== Installing common requirements ====="
# requirements.txt lives in repo root now
pip_install -r "${ROOTDIR}/requirements.txt"

${GPU} && tfgpu='[and-cuda]' || tfgpu=""
echo "   ===== Installing Tensorflow${tfgpu} ====="
##### custom change
# If the image was built from Dockerfile.source-build, a source-compiled wheel
# lives in /opt/tensorflow-wheel/.  Install that wheel instead of downloading
# from PyPI so the venv inherits the same sm_120-capable TF as the system Python.
TF_SOURCE_WHEEL="$(ls /opt/tensorflow-wheel/tensorflow-*.whl 2>/dev/null | head -1)"

if ${GPU} && [ "${TF_VARIANT:-}" = "blackwell" ] ; then
    echo "   ===== TF_VARIANT=blackwell: clean reinstall of TensorFlow for Blackwell (sm_120) ====="
    TF_PKGS="tf-nightly tensorflow tensorflow-gpu ai_edge_litert tensorboard tensorboard-data-server"
    # shellcheck disable=SC2086
    pip uninstall -y $TF_PKGS 2>/dev/null || true
    pip_install --no-cache-dir --upgrade --pre ai_edge_litert "tf-nightly[and-cuda]" "tensorboard" \
        "tensorboard-data-server"
    echo "   ===== TF build info ====="
    python - <<'PY'
import tensorflow as tf
print("tf.__version__:", tf.__version__)
import pprint
pprint.pprint(tf.sysconfig.get_build_info())
print("Physical GPUs:", tf.config.list_physical_devices('GPU'))
PY
elif [ -n "${TF_SOURCE_WHEEL}" ] ; then
    echo "   ===== Source-built TF wheel detected — installing ${TF_SOURCE_WHEEL} ====="
    TF_PKGS="tf-nightly tensorflow tensorflow-gpu"
    # shellcheck disable=SC2086
    pip uninstall -y $TF_PKGS 2>/dev/null || true
    pip_install "${TF_SOURCE_WHEEL}" ai_edge_litert "tensorboard" "tensorboard-data-server"
    echo "   ===== TF build info ====="
    python - <<'PY'
import tensorflow as tf, pprint
print("tf.__version__:", tf.__version__)
pprint.pprint(tf.sysconfig.get_build_info())
print("Physical GPUs:", tf.config.list_physical_devices('GPU'))
PY
else
    pip_install ai_edge_litert "tf-nightly[and-cuda]" "tensorboard" \
        "tensorboard-data-server"
fi

${GPU} && torchgpu='--index-url https://download.pytorch.org/whl/cu129' || torchgpu=""
echo "   ===== Installing torch and torchaudio ${torchgpu:+[cuda]} ====="
pip_install "torch==2.9.1" "torchaudio==2.9.1" ${torchgpu}

echo "   ===== Checking microwakeword ====="
MWW="${DATA_DIR}/tools/microWakeWord"
if [ ! -d "${MWW}" ] || [ -n "$(git -C "${MWW}" status --porcelain)" ] ; then
    rm -rf "${MWW}" || :
    echo "   Cloning micro-wake-word to ${DATA_DIR}/tools"
    git clone https://github.com/Omega-sko/micro-wake-word "${MWW}" &>/dev/null
fi

##### custom change
echo ""
echo "   Patching microwakeword to require tf-nightly"
echo ""
sed -i 's/"tensorflow>=2.16"/"tf-nightly"/g' "${MWW}/setup.py"

# Apply the _to_numpy patch so that model.evaluate() results are handled robustly
# regardless of whether TF returns a Tensor or a plain NumPy array.
# This is necessary because newer tf-nightly builds may return numpy arrays
# instead of EagerTensors, causing bare .numpy() calls to fail.
PATCH_FILE="${ROOTDIR}/patches/micro-wake-word-train-to_numpy.patch"
echo "   Applying micro-wake-word train.py _to_numpy patch"
git -C "${MWW}" apply "${PATCH_FILE}" || {
    echo "ERROR: Failed to apply patch '${PATCH_FILE}' to micro-wake-word." >&2
    echo "       Please check if the upstream train.py has changed and update the patch." >&2
    exit 1
}

echo "   Installing microwakeword"
pip_install -e "${MWW}"

echo "   ===== Checking piper-sample-generator ====="
PSG="${DATA_DIR}/tools/piper-sample-generator"
if [ ! -d "${PSG}" ] || [ -n "$(git -C "${PSG}" status --porcelain)" ] ; then
    rm -rf "${PSG}" || :
    echo "   Cloning piper-sample-generator to ${DATA_DIR}/tools"
    git clone https://github.com/rhasspy/piper-sample-generator "${PSG}" &>/dev/null
fi
echo "   Installing piper-sample-generator"
pip_install -e "${PSG}"
git -C tools/piper-sample-generator clean -fd &>/dev/null

MODELS_DIR="${PSG}/models"
MODEL_NAME="en_US-libritts_r-medium.pt"
MODEL_FILE="${MODELS_DIR}/${MODEL_NAME}"
MODEL_URL="https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/${MODEL_NAME}"
if [ ! -f "${MODEL_FILE}" ] ; then
    echo "      Downloading ${MODEL_NAME} for piper-sample-generator"
    curl -sfL "${MODEL_URL}" -o "${MODEL_FILE}"
fi

if [ ! -f "${MODEL_FILE}.json" ] ; then
    echo "      Downloading ${MODEL_NAME}.json for piper-sample-generator"
    curl -sfL "${MODEL_URL}.json" -o "${MODEL_FILE}.json"
fi

${GPU} && onnxgpu='-gpu[cuda]' || onnxgpu=""
echo "   ===== Installing onnxruntime${onnxgpu} ====="
pip_install "onnxruntime${onnxgpu}>=1.16.0"

echo "   ===== Installing keras ====="
# keras 3.13 has "issues" so we need to back down to 3.12.
pip_install "keras==3.12.0"

# -----------------------------------------------------------------------------
# Optional CUDA data dir (GPU-only)
# Some stacks expect a CUDA "nvvm/libdevice" tree. We create one in /data/cuda
# and link Triton's libdevice if it exists. This is safe and does NOT enable
# any extra XLA flags by itself.
# -----------------------------------------------------------------------------
if ${GPU} ; then
    CUDA_DATA_DIR="${DATA_DIR}/cuda"
    LIBDEVICE_DIR="${CUDA_DATA_DIR}/nvvm/libdevice"
    mkdir -p "${LIBDEVICE_DIR}"

    TRITON_LIBDEVICE="$(
        python - <<'PY'
import glob
paths = glob.glob("**/site-packages/triton/backends/nvidia/lib/libdevice.10.bc", recursive=True)
print(paths[0] if paths else "", end="")
PY
    )"

    if [ -n "${TRITON_LIBDEVICE}" ] ; then
        ln -sf "${TRITON_LIBDEVICE}" "${LIBDEVICE_DIR}/libdevice.10.bc"
        echo "   Linked Triton libdevice.10.bc to ${LIBDEVICE_DIR}"
    else
        echo "   ℹ️  Triton libdevice.10.bc not found (ok)"
    fi
fi

"${PROGDIR}/test_python" --data-dir="${DATA_DIR}"

touch .mww-data-dir
END_TS=$EPOCHSECONDS

echo "Run 'source ${VENV}/bin/activate' to activate the new virtualenv in the current shell."

print_elapsed_time "${START_TS}" "${END_TS}" "Python package installation complete"
